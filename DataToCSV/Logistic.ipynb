{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\USER\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "import sys\n",
    "maxInt = sys.maxsize\n",
    "\n",
    "while True:\n",
    "    try:\n",
    "        csv.field_size_limit(maxInt)\n",
    "        break\n",
    "    except OverflowError:\n",
    "        maxInt = int(maxInt/10)\n",
    "\n",
    "import numpy as np \n",
    "import pandas as pd \n",
    "import glob\n",
    "import json\n",
    "import regex as re\n",
    "import gensim\n",
    "import gensim.downloader as api\n",
    "from gensim.models.doc2vec import TaggedDocument, Doc2Vec \n",
    "from gensim.test.utils import get_tmpfile\n",
    "\n",
    "from gensim.test.utils import common_texts\n",
    "from gensim.models.doc2vec import Doc2Vec, TaggedDocument\n",
    "from sklearn.metrics import accuracy_score, f1_score, recall_score, classification_report\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import OneClassSVM\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn import utils, tree\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "import random\n",
    "\n",
    "from tqdm import tqdm\n",
    "import multiprocessing\n",
    "import nltk\n",
    "nltk.download('punkt')\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "from keras.utils.np_utils import to_categorical\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Embedding, LSTM, SpatialDropout1D, Dropout\n",
    "\n",
    "from collections import defaultdict\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import heapq\n",
    "\n",
    "import pickle\n",
    "import joblib\n",
    "\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"/Users/USER/Desktop/project/cleaned_data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "employee = df['employee']\n",
    "def dupli(x):\n",
    "    return list(dict.fromkeys(x))\n",
    "employee = dupli(employee)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "employee_index = {}\n",
    "index_count = 1\n",
    "for i in employee:\n",
    "    employee_index[i] = index_count\n",
    "    index_count += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'allen-p': 1,\n",
       " 'arnold-j': 2,\n",
       " 'bass-e': 3,\n",
       " 'baughman-d': 4,\n",
       " 'beck-s': 5,\n",
       " 'blair-l': 6,\n",
       " 'brawner-s': 7,\n",
       " 'buy-r': 8,\n",
       " 'campbell-l': 9,\n",
       " 'carson-m': 10,\n",
       " 'cash-m': 11,\n",
       " 'corman-s': 12,\n",
       " 'cuilla-m': 13,\n",
       " 'dasovich-j': 14,\n",
       " 'davis-d': 15,\n",
       " 'dean-c': 16,\n",
       " 'delainey-d': 17,\n",
       " 'derrick-j': 18,\n",
       " 'donoho-l': 19,\n",
       " 'donohoe-t': 20,\n",
       " 'dorland-c': 21,\n",
       " 'ermis-f': 22,\n",
       " 'farmer-d': 23,\n",
       " 'fischer-m': 24,\n",
       " 'fossum-d': 25,\n",
       " 'gay-r': 26,\n",
       " 'geaccone-t': 27,\n",
       " 'germany-c': 28,\n",
       " 'giron-d': 29,\n",
       " 'griffith-j': 30,\n",
       " 'grigsby-m': 31,\n",
       " 'guzman-m': 32,\n",
       " 'haedicke-m': 33,\n",
       " 'hain-m': 34,\n",
       " 'hayslett-r': 35,\n",
       " 'heard-m': 36,\n",
       " 'hernandez-j': 37,\n",
       " 'hodge-j': 38,\n",
       " 'horton-s': 39,\n",
       " 'hyatt-k': 40,\n",
       " 'hyvl-d': 41,\n",
       " 'jones-t': 42,\n",
       " 'kaminski-v': 43,\n",
       " 'kean-s': 44,\n",
       " 'keavey-p': 45,\n",
       " 'keiser-k': 46,\n",
       " 'kitchen-l': 47,\n",
       " 'kuykendall-t': 48,\n",
       " 'lavorato-j': 49,\n",
       " 'lay-k': 50,\n",
       " 'lenhart-m': 51,\n",
       " 'lewis-a': 52,\n",
       " 'linder-e': 53,\n",
       " 'lokay-m': 54,\n",
       " 'lokey-t': 55,\n",
       " 'love-p': 56,\n",
       " 'maggi-m': 57,\n",
       " 'mann-k': 58,\n",
       " 'martin-t': 59,\n",
       " 'may-l': 60,\n",
       " 'mcconnell-m': 61,\n",
       " 'mclaughlin-e': 62,\n",
       " 'merriss-s': 63,\n",
       " 'meyers-a': 64,\n",
       " 'mims-thurston-p': 65,\n",
       " 'neal-s': 66,\n",
       " 'nemec-g': 67,\n",
       " 'parks-j': 68,\n",
       " 'perlingiere-d': 69,\n",
       " 'presto-k': 70,\n",
       " 'quigley-d': 71,\n",
       " 'rodrique-r': 72,\n",
       " 'rogers-b': 73,\n",
       " 'ruscitti-k': 74,\n",
       " 'sager-e': 75,\n",
       " 'saibi-e': 76,\n",
       " 'salisbury-h': 77,\n",
       " 'sanders-r': 78,\n",
       " 'schoolcraft-d': 79,\n",
       " 'scott-s': 80,\n",
       " 'shackleton-s': 81,\n",
       " 'shankman-j': 82,\n",
       " 'shapiro-r': 83,\n",
       " 'shively-h': 84,\n",
       " 'skilling-j': 85,\n",
       " 'smith-m': 86,\n",
       " 'solberg-g': 87,\n",
       " 'stclair-c': 88,\n",
       " 'steffes-j': 89,\n",
       " 'stepenovitch-j': 90,\n",
       " 'stokley-c': 91,\n",
       " 'storey-g': 92,\n",
       " 'sturm-f': 93,\n",
       " 'symes-k': 94,\n",
       " 'taylor-m': 95,\n",
       " 'tholt-j': 96,\n",
       " 'thomas-p': 97,\n",
       " 'tycholiz-b': 98,\n",
       " 'ward-k': 99,\n",
       " 'watson-k': 100,\n",
       " 'weldon-c': 101,\n",
       " 'whalley-g': 102,\n",
       " 'whalley-l': 103,\n",
       " 'white-s': 104,\n",
       " 'williams-j': 105,\n",
       " 'williams-w3': 106,\n",
       " 'wolfe-j': 107,\n",
       " 'ybarbo-p': 108,\n",
       " 'zipper-a': 109}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "employee_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the DataFrame to a dictionary\n",
    "data = defaultdict(list)\n",
    "for index, row in df.iterrows():\n",
    "    label = row[3]\n",
    "    text = row[2]\n",
    "    data[label].append(text)\n",
    "\n",
    "# Shuffle the data\n",
    "for label in data:\n",
    "    random.shuffle(data[label])\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "train_data = {}\n",
    "test_data = {}\n",
    "for label in data:\n",
    "    train_data[label], test_data[label] = train_test_split(data[label], test_size=0.2)\n",
    "\n",
    "# Tokenize the data\n",
    "for label in train_data:\n",
    "    train_data[label] = [word_tokenize(text) for text in train_data[label]]\n",
    "for label in test_data:\n",
    "    test_data[label] = [word_tokenize(text) for text in test_data[label]]\n",
    "\n",
    "# Store the data in a dictionary\n",
    "data_dict = {}\n",
    "for label in train_data:\n",
    "    data_dict[label] = (train_data[label], test_data[label])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "label = \"donoho-l\"\n",
    "train_data = data_dict[label][0]\n",
    "text = train_data[50]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['--',\n",
       " 'Lindy',\n",
       " ':',\n",
       " 'Below',\n",
       " 'are',\n",
       " 'our',\n",
       " 'flight',\n",
       " 'arrangements',\n",
       " 'Omaha/Houston',\n",
       " 'roundtrip',\n",
       " '.',\n",
       " 'The',\n",
       " 'rental',\n",
       " 'car',\n",
       " 'information',\n",
       " 'is',\n",
       " 'not',\n",
       " 'included',\n",
       " '(',\n",
       " 'did',\n",
       " \"n't\",\n",
       " 'think',\n",
       " 'you',\n",
       " 'would',\n",
       " 'need',\n",
       " ')',\n",
       " '.',\n",
       " 'We',\n",
       " 'are',\n",
       " 'really',\n",
       " 'looking',\n",
       " 'forward',\n",
       " 'to',\n",
       " 'our',\n",
       " 'visit',\n",
       " 'and',\n",
       " 'especially',\n",
       " 'to',\n",
       " 'see',\n",
       " 'Sam',\n",
       " '!',\n",
       " '!',\n",
       " 'See',\n",
       " 'you',\n",
       " 'on',\n",
       " 'Thursday',\n",
       " '.',\n",
       " 'Love',\n",
       " '.',\n",
       " 'Flo',\n",
       " '--',\n",
       " '--',\n",
       " '--',\n",
       " '--',\n",
       " '--',\n",
       " '--',\n",
       " '--',\n",
       " '--',\n",
       " '--',\n",
       " '--',\n",
       " '--',\n",
       " '--',\n",
       " '--',\n",
       " '--',\n",
       " '--',\n",
       " '--',\n",
       " '--',\n",
       " '--',\n",
       " '--',\n",
       " '--',\n",
       " '--',\n",
       " '--',\n",
       " '--',\n",
       " '--',\n",
       " '--',\n",
       " '--',\n",
       " '--',\n",
       " '--',\n",
       " '--',\n",
       " '--',\n",
       " '--',\n",
       " '--',\n",
       " '--',\n",
       " '--',\n",
       " '--',\n",
       " '--',\n",
       " '--',\n",
       " '-',\n",
       " '*',\n",
       " '*',\n",
       " '*',\n",
       " 'FLIGHT',\n",
       " 'ITINERARY',\n",
       " '*',\n",
       " '*',\n",
       " '*',\n",
       " 'Flight',\n",
       " 'Itinerary',\n",
       " ':',\n",
       " 'Round',\n",
       " 'Trip',\n",
       " ',',\n",
       " 'Omaha',\n",
       " ',',\n",
       " 'NE',\n",
       " 'to',\n",
       " 'Houston',\n",
       " ',',\n",
       " 'TX',\n",
       " 'Hotwire',\n",
       " 'Itinerary',\n",
       " 'Number',\n",
       " ':',\n",
       " 'PKR5VX6A7W',\n",
       " 'If',\n",
       " 'you',\n",
       " 'need',\n",
       " 'to',\n",
       " 'contact',\n",
       " 'Hotwire',\n",
       " 'Customer',\n",
       " 'Care',\n",
       " ',',\n",
       " 'please',\n",
       " 'have',\n",
       " 'your',\n",
       " 'itinerary',\n",
       " 'number',\n",
       " 'available',\n",
       " '.',\n",
       " 'We',\n",
       " 'can',\n",
       " 'be',\n",
       " 'reached',\n",
       " 'toll-free',\n",
       " 'at',\n",
       " '1-877-HOTWIRE',\n",
       " '(',\n",
       " '468-9473',\n",
       " ')',\n",
       " '.',\n",
       " 'Airline',\n",
       " ':',\n",
       " 'American',\n",
       " 'Airlines',\n",
       " 'Departure',\n",
       " 'American',\n",
       " 'Airlines',\n",
       " 'Flight',\n",
       " '479',\n",
       " 'Departing',\n",
       " ':',\n",
       " 'Omaha',\n",
       " '(',\n",
       " 'OMA',\n",
       " ')',\n",
       " 'Thu',\n",
       " '24-Jan-02',\n",
       " ',',\n",
       " '11:43am',\n",
       " 'Arriving',\n",
       " ':',\n",
       " 'Houston',\n",
       " '(',\n",
       " 'IAH',\n",
       " ')',\n",
       " 'Thu',\n",
       " '24-Jan-02',\n",
       " ',',\n",
       " '3:43pm',\n",
       " '1',\n",
       " 'stop',\n",
       " ':',\n",
       " 'Dallas/Fort',\n",
       " 'Worth',\n",
       " '(',\n",
       " 'DFW',\n",
       " ')',\n",
       " 'Return',\n",
       " 'American',\n",
       " 'Airlines',\n",
       " 'Flight',\n",
       " '2990',\n",
       " 'Departing',\n",
       " ':',\n",
       " 'Houston',\n",
       " '(',\n",
       " 'IAH',\n",
       " ')',\n",
       " 'Mon',\n",
       " '28-Jan-02',\n",
       " ',',\n",
       " '2:18pm',\n",
       " 'Arriving',\n",
       " ':',\n",
       " 'Saint',\n",
       " 'Louis',\n",
       " '(',\n",
       " 'STL',\n",
       " ')',\n",
       " 'Mon',\n",
       " '28-Jan-02',\n",
       " ',',\n",
       " '4:15pm',\n",
       " 'Operated',\n",
       " 'by',\n",
       " 'Twa',\n",
       " 'Nonstop',\n",
       " 'Connecting',\n",
       " 'American',\n",
       " 'Airlines',\n",
       " 'Flight',\n",
       " '5741',\n",
       " 'Departing',\n",
       " ':',\n",
       " 'Saint',\n",
       " 'Louis',\n",
       " '(',\n",
       " 'STL',\n",
       " ')',\n",
       " 'Mon',\n",
       " '28-Jan-02',\n",
       " ',',\n",
       " '5:36pm',\n",
       " 'Arriving',\n",
       " ':',\n",
       " 'Omaha',\n",
       " '(',\n",
       " 'OMA',\n",
       " ')',\n",
       " 'Mon',\n",
       " '28-Jan-02',\n",
       " ',',\n",
       " '6:59pm',\n",
       " 'Operated',\n",
       " 'by',\n",
       " 'Chautauqua/Dba',\n",
       " 'American',\n",
       " 'Connection',\n",
       " 'Nonstop',\n",
       " 'For',\n",
       " 'better',\n",
       " 'deals',\n",
       " 'on',\n",
       " 'flights',\n",
       " ',',\n",
       " 'hotels',\n",
       " 'and',\n",
       " 'car',\n",
       " 'rentals',\n",
       " ',',\n",
       " 'visit',\n",
       " 'Hotwire',\n",
       " 'today',\n",
       " '!',\n",
       " '-',\n",
       " 'The',\n",
       " 'Hotwire',\n",
       " 'Team',\n",
       " 'http',\n",
       " ':',\n",
       " '//www.hotwire.com']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the size of the vector representation of each document\n",
    "vector_size = 100\n",
    "\n",
    "# Define the parameters for training the Doc2Vec model\n",
    "max_epochs = 40\n",
    "alpha = 0.025\n",
    "min_alpha = 0.00025\n",
    "num_cores = 8  \n",
    "\n",
    "# Create an empty Doc2Vec model\n",
    "model = Doc2Vec(vector_size=vector_size, min_count=2, epochs=max_epochs, workers=num_cores)\n",
    "\n",
    "# Define a function to convert text into TaggedDocuments\n",
    "def tag_docs(data, label):\n",
    "    tagged_docs = []\n",
    "    for i, text in enumerate(data):\n",
    "        doc = TaggedDocument(words=text, tags=[label + '_%s' % i])\n",
    "        tagged_docs.append(doc)\n",
    "    return tagged_docs\n",
    "\n",
    "# Create TaggedDocuments for the training data\n",
    "train_tagged = []\n",
    "for label in train_data:\n",
    "    train_tagged += tag_docs(train_data[label], label)\n",
    "\n",
    "# Build the vocabulary\n",
    "model.build_vocab(train_tagged)\n",
    "\n",
    "# Train the model\n",
    "model.train(train_tagged, total_examples=model.corpus_count, epochs=model.epochs)\n",
    "\n",
    "# Create TaggedDocuments for the testing data\n",
    "test_tagged = {}\n",
    "for label in test_data:\n",
    "    test_tagged[label] = tag_docs(test_data[label], label)\n",
    "\n",
    "# Get the document vectors for the training and testing data\n",
    "train_vecs = {}\n",
    "for label in train_data:\n",
    "    train_vecs[label] = [model.dv[label + '_%s' % i] for i in range(len(train_data[label]))]\n",
    "test_vecs = {}\n",
    "for label in test_data:\n",
    "    test_vecs[label] = [model.infer_vector(doc.words) for doc in test_tagged[label]]\n",
    "\n",
    "# Store the data in a dictionary\n",
    "data_dict = {}\n",
    "for label in train_data:\n",
    "    data_dict[label] = (train_vecs[label], test_vecs[label])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the trained model to a file\n",
    "model.save(\"doc2vec_svm.bin\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.5440904907469932\n"
     ]
    }
   ],
   "source": [
    "# Define a function to train a one-class SVM model for a given label\n",
    "def train_one_class_svm(train_vecs, train_data, label):\n",
    "    positive_class = label  # choose one class as the positive class\n",
    "    X_pos = train_vecs[positive_class]\n",
    "    X_neg = np.concatenate([train_vecs[l] for l in train_data if l != positive_class])\n",
    "    np.random.shuffle(X_neg)  # shuffle the negative training set\n",
    "    X_neg_sample = X_neg[:10000]  # randomly sample 50,000 negative training samples\n",
    "    model = OneClassSVM(kernel='linear')\n",
    "    model.fit(X_pos)\n",
    "    return model, X_neg_sample\n",
    "\n",
    "# Train one-class SVM models for all labels\n",
    "models = {}\n",
    "for label in train_data:\n",
    "    model, X_neg_sample = train_one_class_svm(train_vecs, train_data, label)\n",
    "    models[label] = (model, X_neg_sample)\n",
    "\n",
    "# Test the models on the testing data\n",
    "predictions = []\n",
    "true_labels = []\n",
    "for label in test_data:\n",
    "    model, X_neg_sample = models[label]\n",
    "    y_pred_pos = model.predict(test_vecs[label])\n",
    "    y_pred_neg = model.predict(X_neg_sample)\n",
    "    y_pred = np.concatenate([y_pred_pos, y_pred_neg])\n",
    "    predictions += list(y_pred)\n",
    "    true_labels += [1] * len(y_pred_pos) + [-1] * len(y_pred_neg)\n",
    "\n",
    "# Calculate the accuracy\n",
    "accuracy = accuracy_score(true_labels, predictions)\n",
    "print(\"Accuracy:\", accuracy)\n",
    "\n",
    "# Save all the trained models\n",
    "with open('models.pkl', 'wb') as f:\n",
    "    pickle.dump(models, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save all the trained models\n",
    "with open('models.pkl', 'wb') as f:\n",
    "    pickle.dump(models, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Calculate the accuracy for each label\n",
    "label_accuracy = {}\n",
    "for label in test_data:\n",
    "    model, X_neg_sample = models[label]\n",
    "    y_pred_pos = model.predict(test_vecs[label])\n",
    "    y_pred_neg = model.predict(X_neg_sample)\n",
    "    y_pred = np.concatenate([y_pred_pos, y_pred_neg])\n",
    "    true_labels = [1] * len(y_pred_pos) + [-1] * len(y_pred_neg)\n",
    "    label_accuracy[label] = accuracy_score(true_labels, y_pred)\n",
    "\n",
    "# Create a bar plot of the accuracy scores\n",
    "plt.bar(label_accuracy.keys(), label_accuracy.values())\n",
    "plt.title('Accuracy by Label')\n",
    "plt.xlabel('Label')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.9269631116329496\n",
      "Recall: 0.5482935779816513\n",
      "F1-score: 0.6890298138787097\n",
      "Confusion matrix:\n",
      "[[597640 492360]\n",
      " [ 47089  46148]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix, precision_recall_fscore_support\n",
    "\n",
    "# Test the models on the testing data\n",
    "y_pred = []\n",
    "y_true = []\n",
    "for label in test_data:\n",
    "    model, X_neg_sample = models[label]\n",
    "    y_pred_pos = model.predict(test_vecs[label])\n",
    "    y_pred_neg = model.predict(X_neg_sample)\n",
    "    y_pred.extend(list(y_pred_pos) + list(y_pred_neg))\n",
    "    y_true.extend([1] * len(y_pred_pos) + [-1] * len(y_pred_neg))\n",
    "\n",
    "# Calculate the evaluation metrics\n",
    "precision, recall, f1, _ = precision_recall_fscore_support(y_true, y_pred, pos_label=-1, average='binary')\n",
    "confusion = confusion_matrix(y_true, y_pred)\n",
    "\n",
    "# Print the evaluation metrics\n",
    "print('Precision:', precision)\n",
    "print('Recall:', recall)\n",
    "print('F1-score:', f1)\n",
    "print('Confusion matrix:')\n",
    "print(confusion)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "1d5c1156327dacead463cc502c55ebae8ce9c8c01979cf154173ff808e75bf55"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
