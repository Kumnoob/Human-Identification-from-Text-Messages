{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\USER\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "import sys\n",
    "maxInt = sys.maxsize\n",
    "\n",
    "while True:\n",
    "    try:\n",
    "        csv.field_size_limit(maxInt)\n",
    "        break\n",
    "    except OverflowError:\n",
    "        maxInt = int(maxInt/10)\n",
    "\n",
    "import numpy as np \n",
    "import pandas as pd \n",
    "import glob\n",
    "import json\n",
    "import regex as re\n",
    "import gensim\n",
    "import gensim.downloader as api\n",
    "from gensim.models.doc2vec import TaggedDocument, Doc2Vec \n",
    "from gensim.test.utils import get_tmpfile\n",
    "\n",
    "from gensim.test.utils import common_texts\n",
    "from gensim.models.doc2vec import Doc2Vec, TaggedDocument\n",
    "from sklearn.metrics import accuracy_score, f1_score, recall_score, classification_report\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import OneClassSVM\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn import utils, tree\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "import random\n",
    "\n",
    "from tqdm import tqdm\n",
    "import multiprocessing\n",
    "import nltk\n",
    "nltk.download('punkt')\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "from keras.utils.np_utils import to_categorical\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Embedding, LSTM, SpatialDropout1D, Dropout\n",
    "\n",
    "from collections import defaultdict\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import heapq\n",
    "\n",
    "import pickle\n",
    "import joblib\n",
    "\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'allen-p': -1, 'arnold-j': -1, 'bass-e': -1, 'baughman-d': -1, 'beck-s': -1, 'blair-l': -1, 'brawner-s': -1, 'buy-r': -1, 'campbell-l': -1, 'carson-m': -1, 'cash-m': -1, 'corman-s': -1, 'cuilla-m': -1, 'dasovich-j': -1, 'davis-d': -1, 'dean-c': -1, 'delainey-d': -1, 'derrick-j': -1, 'donoho-l': -1, 'donohoe-t': -1, 'dorland-c': -1, 'ermis-f': -1, 'farmer-d': -1, 'fischer-m': -1, 'fossum-d': -1, 'gay-r': -1, 'geaccone-t': -1, 'germany-c': -1, 'giron-d': -1, 'griffith-j': -1, 'grigsby-m': -1, 'guzman-m': -1, 'haedicke-m': -1, 'hain-m': -1, 'hayslett-r': -1, 'heard-m': -1, 'hernandez-j': -1, 'hodge-j': -1, 'horton-s': -1, 'hyatt-k': -1, 'hyvl-d': -1, 'jones-t': -1, 'kaminski-v': -1, 'kean-s': -1, 'keavey-p': -1, 'keiser-k': -1, 'kitchen-l': -1, 'kuykendall-t': -1, 'lavorato-j': -1, 'lay-k': -1, 'lenhart-m': -1, 'lewis-a': -1, 'linder-e': -1, 'lokay-m': -1, 'lokey-t': -1, 'love-p': -1, 'maggi-m': -1, 'mann-k': -1, 'martin-t': -1, 'may-l': -1, 'mcconnell-m': -1, 'mclaughlin-e': -1, 'merriss-s': -1, 'meyers-a': 1, 'mims-thurston-p': -1, 'neal-s': -1, 'nemec-g': -1, 'parks-j': -1, 'perlingiere-d': -1, 'presto-k': -1, 'quigley-d': -1, 'rodrique-r': -1, 'rogers-b': -1, 'ruscitti-k': -1, 'sager-e': -1, 'saibi-e': -1, 'salisbury-h': -1, 'sanders-r': -1, 'schoolcraft-d': -1, 'scott-s': -1, 'shackleton-s': -1, 'shankman-j': -1, 'shapiro-r': -1, 'shively-h': -1, 'skilling-j': -1, 'smith-m': -1, 'solberg-g': -1, 'stclair-c': -1, 'steffes-j': -1, 'stepenovitch-j': -1, 'stokley-c': -1, 'storey-g': -1, 'sturm-f': -1, 'symes-k': -1, 'taylor-m': -1, 'tholt-j': -1, 'thomas-p': -1, 'tycholiz-b': -1, 'ward-k': -1, 'watson-k': -1, 'weldon-c': -1, 'whalley-g': -1, 'whalley-l': -1, 'white-s': -1, 'williams-j': -1, 'williams-w3': -1, 'wolfe-j': -1, 'ybarbo-p': -1, 'zipper-a': -1}\n"
     ]
    }
   ],
   "source": [
    "# Load the Doc2Vec model\n",
    "doc2vec_model = gensim.models.Doc2Vec.load('doc2vec_svm.bin')\n",
    "\n",
    "# Load the models\n",
    "with open('models.pkl', 'rb') as f:\n",
    "    models = pickle.load(f)\n",
    "\n",
    "svm_models = {}\n",
    "for label in models:\n",
    "    model, X_neg_sample = models[label]\n",
    "    svm_models[label] = (model, X_neg_sample)\n",
    "\n",
    "# Define a function to make predictions on a new input string\n",
    "def predict(input_string):\n",
    "    # Convert the input string to a vector using the Doc2Vec model\n",
    "    input_vec = doc2vec_model.infer_vector(input_string.split())\n",
    "\n",
    "    # Make predictions for each SVM model\n",
    "    predictions = {}\n",
    "    for label in svm_models:\n",
    "        model, X_neg_sample = svm_models[label]\n",
    "        y_pred_pos = model.predict([input_vec])\n",
    "        y_pred_neg = model.predict(X_neg_sample)\n",
    "        y_pred = np.concatenate([y_pred_pos, y_pred_neg])\n",
    "        predictions[label] = y_pred[0]\n",
    "\n",
    "    return predictions\n",
    "\n",
    "# Example usage\n",
    "input_string = \"This is a new input string.\"\n",
    "predictions = predict(input_string)\n",
    "print(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "meyers-a\n"
     ]
    }
   ],
   "source": [
    "# Find the key with value 1\n",
    "output = None\n",
    "for key, value in predictions.items():\n",
    "    if value == 1:\n",
    "        output = key\n",
    "        break\n",
    "\n",
    "print(output)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
